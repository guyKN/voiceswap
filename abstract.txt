Over 10 million people live with voice disabilities or voicelessness. Some diseases like ALS cause people to lose their voice over a long time. They rely on text-to-speech devices to express themselves. Current text to speech systems produce robot-like voices, which are nothing like their real voices.
The goal of this project is to allow people, especially kids like these the choice of a specific voice they like (for example, a celebrity). For people who suffer from ALS or similar diseases, they could record themselves talking and then use their own voice. 
My evaluation criteria was that Phonexia, a program that tells if two voices come from the same speaker, will classify the original and new voice as the same person. My constraints where time and money.
I used Neural Networks (NNs) for to accomplish the goal. One of the problems with  machine learning algorithms is that massive amounts of training data is needed, and such data is not freely available. To get around this, my idea was to download audio from YouTube. I used the subtitles and then text-to-speech to create pairs of audio files saying the same things.
After Training, I took text inputs from users and then then turned it into speech with Google’s text to speech. Then I used my already trained neural network with the outputted speech as input and that should output the Target person speaking. 
Unfortunately the output didn’t sound like anything. It was a Brrrr sound. This was probably caused by unaligned signals. I tried using dynamic time warping (DTW). DTW is a method for aligning two signals. However the sound ended up sounding too weird. A next step would be improving DTW and fixing the problem.
